{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import LSTM, Dropout,Dense, BatchNormalization, GRU\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import regularizers\n",
    "from pickle import dump\n",
    "# from tcn import TCN, tcn_full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_of_focus = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file\n",
    "\n",
    "#set your music file path\n",
    "directory = '../input/seperation'\n",
    "order = ['bass', 'drums', 'other', 'piano', 'vocals']\n",
    "# total_df = []\n",
    "sep_df = [[] for _ in order]\n",
    "count=0\n",
    "for x in range(10):\n",
    "    print(x)\n",
    "#     total_df.append(pd.read_csv(directory + '/total' + str(x) + '.csv', index_col=0))\n",
    "    for index, cat in enumerate(order):\n",
    "        \n",
    "        if(index == category_of_focus):\n",
    "            print(index)\n",
    "            sep_df[index].append(pd.read_csv(directory + '/' + cat + str(x) + '.csv', index_col=0))\n",
    "#concatenate into a long sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VAL = 32768\n",
    "means = []\n",
    "# total = pd.concat(total_df) / MAX_VAL\n",
    "sep = []\n",
    "\n",
    "for index in range(len(order)):\n",
    "    if(index == category_of_focus):\n",
    "        sep.append(pd.concat(sep_df[index]) / MAX_VAL)\n",
    "    else:\n",
    "        sep.append(pd.DataFrame())\n",
    "del sep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_songs = len(sep[category_of_focus])\n",
    "duration = len(sep[category_of_focus].iloc[0])\n",
    "seq_combined = np.zeros((num_songs, duration, 5))\n",
    "for s in range(num_songs):\n",
    "    for c in range(5):\n",
    "        if (c == category_of_focus):\n",
    "            seq_combined[s, :, c] = sep[c].iloc[s]\n",
    "del sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/unnati-xyz/music-generation/blob/16438a4d4ecb4645007be2d87a053cc904ebe780/data_utils/parse_files.py#L196\n",
    "def time_blocks_to_fft_blocks(blocks_time_domain):\n",
    "    fft_blocks = []\n",
    "    plot_block=[]\n",
    "    amplitude = []\n",
    "    for block in blocks_time_domain:\n",
    "        '''print(\"block=\",block)'''\n",
    "        # Computes the one-dimensional discrete Fourier Transform and returns the complex nD array\n",
    "        # i.e The truncated or zero-padded input, transformed along the axis indicated by axis, or the last one if axis is not specified.\n",
    "        fft_block = np.fft.fft(block)\n",
    "#         new_block = np.zeros((block.shape[0], 2))\n",
    "#         new_block[:, 0] = np.real(fft_block)\n",
    "#         new_block[:, 1] = np.imag(fft_block)\n",
    "        new_block = np.concatenate(\n",
    "                (np.real(fft_block), np.imag(fft_block)))  # Joins a sequence of arrays along an existing axis.\n",
    "        fft_blocks.append(new_block)\n",
    "        #plot_block.append(fft_block)\n",
    "    \n",
    "    return np.array(fft_blocks)\n",
    "\n",
    "\n",
    "def fft_blocks_to_time_blocks(blocks_ft_domain):\n",
    "    time_blocks = []\n",
    "    for block in blocks_ft_domain:\n",
    "        num_elems = block.shape[0] // 2\n",
    "        real_chunk = block[0:num_elems]\n",
    "        imag_chunk = block[num_elems:]\n",
    "        new_block = real_chunk + 1.0j * imag_chunk\n",
    "        time_block = np.fft.ifft(new_block)\n",
    "        time_blocks.append(time_block)\n",
    "    return np.array(time_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create sub sequences from a big sequence\n",
    "def to_sequences(dataset, seq_size=1, output_len=300, stride = 150):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(0,len(dataset)-seq_size-output_len,stride):\n",
    "        window = dataset[i:(i+seq_size)]\n",
    "        x.append(window)\n",
    "        y.append(dataset[i+seq_size:i+seq_size+output_len])\n",
    "        \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create sub sequences from a big sequence\n",
    "def chunk(dataset, seq_size=1, stride = 1):\n",
    "    x = []\n",
    "    for i in range(0,len(dataset)-seq_size,stride):\n",
    "        window = dataset[i:(i+seq_size)]\n",
    "        x.append(window)\n",
    "        \n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500\n",
    "fftb = []\n",
    "for x in range(len(seq_combined)):\n",
    "    fftb.append(time_blocks_to_fft_blocks(chunk(seq_combined[x, :, category_of_focus], chunk_size, chunk_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_combined = np.array(fftb)\n",
    "input_len = 20\n",
    "output_len = 20\n",
    "stride = 1\n",
    "\n",
    "x_sequences = []\n",
    "y_sequences = []\n",
    "for x in range(num_songs):\n",
    "    temp_x, temp_y = to_sequences(fft_combined[x,:,:], seq_size = input_len, output_len = output_len, stride = stride)\n",
    "    x_sequences.append(temp_x)\n",
    "    y_sequences.append(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fftb\n",
    "del fft_combined\n",
    "len(x_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "x_sequences = np.concatenate(x_sequences)\n",
    "y_sequences = np.concatenate(y_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "num_data = len(x_sequences)\n",
    "x_test = x_sequences[int(0.9*num_data):]\n",
    "y_test = x_sequences[int(0.9*num_data):]\n",
    "x_train = x_sequences[:int(0.9*num_data)]\n",
    "y_train = x_sequences[:int(0.9*num_data)]\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "np.random.shuffle(y_test)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "del x_sequences\n",
    "del y_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/unnati-xyz/music-generation/blob/16438a4d4ecb4645007be2d87a053cc904ebe780/config/nn_config.py#L1\n",
    "def create_lstm_network(num_frequency_dimensions, num_hidden_dimensions, num_recurrent_units=1, input_len = 7, output_len = 1):\n",
    "    model = tf.keras.Sequential()  # Sequential is a linear stack of layers\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = (input_len, num_frequency_dimensions)))\n",
    "    # This layer converts frequency space to hidden space\n",
    "    model.add(tf.keras.layers.TimeDistributed(Dense(num_hidden_dimensions)))\n",
    "    for cur_unit in range(num_recurrent_units):\n",
    "        # return_sequences=True implies return the entire output sequence & not just the last output\n",
    "        model.add(tf.keras.layers.LSTM(num_hidden_dimensions, return_sequences=True))\n",
    "    # This layer converts hidden space back to frequency space\n",
    "    model.add(tf.keras.layers.TimeDistributed(Dense(num_hidden_dimensions)))\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: x[:,-3:,:]))\n",
    "    model.add(tf.keras.layers.Reshape((3 * num_hidden_dimensions, )))\n",
    "    model.add(tf.keras.layers.Dense(output_len * num_frequency_dimensions))\n",
    "#     model.add(tf.keras.layers.Lambda(lambda x: x[:,-1,:]))\n",
    "    model.add(tf.keras.layers.Reshape((output_len,num_frequency_dimensions)))\n",
    "\n",
    "    # Done building the model.Now, configure it for the learning process\n",
    "#     model.compile(loss='mean_absolute_error', optimizer='rmsprop')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_decoder(num_frequency_dimensions, num_hidden_dimensions, num_recurrent_units=1, input_len = 7, output_len = 1):\n",
    "    model = tf.keras.Sequential()  # Sequential is a linear stack of layers\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = (input_len, num_frequency_dimensions)))\n",
    "    # This layer converts frequency space to hidden space\n",
    "    model.add(tf.keras.layers.TimeDistributed(Dense(num_hidden_dimensions)))\n",
    "    for cur_unit in range(num_recurrent_units):\n",
    "        # return_sequences=True implies return the entire output sequence & not just the last output\n",
    "        model.add(tf.keras.layers.LSTM(num_hidden_dimensions, return_sequences=False))\n",
    "    # This layer converts hidden space back to frequency space\n",
    "    \n",
    "    model.add(tf.keras.layers.RepeatVector(input_len))\n",
    "    model.add(tf.keras.layers.LSTM(2048, activation='relu', return_sequences=True))\n",
    "    model.add(tf.keras.layers.TimeDistributed(Dense(num_frequency_dimensions)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_encoder_decoder(2 * chunk_size, 2048, num_recurrent_units = 1, input_len = input_len, output_len = output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_lstm_network(2 * chunk_size, 2048, num_recurrent_units = 1, input_len = input_len, output_len = output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lr in [0.01, 0.005, 0.001, 0.001]:\n",
    "\n",
    "# trained at 0.0001 for 200 epochs\n",
    "lr = 0.00005\n",
    "# for lr in [0.0001, 0.00005]:\n",
    "print()\n",
    "print(lr)\n",
    "opt = tf.optimizers.Adam(lr=lr)\n",
    "met = tf.metrics.MeanAbsoluteError()\n",
    "model.compile(loss=tf.losses.MSE, optimizer=opt, metrics=[met])\n",
    "model.fit(x_train, y_train, epochs=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train[0:100])\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTest = model.predict(x_test[0:100])\n",
    "predTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songnum = 1\n",
    "# plt.plot(X[songnum,:, 0] * 100)\n",
    "actual_song = np.concatenate((fft_blocks_to_time_blocks(x_train[songnum]).flatten(), fft_blocks_to_time_blocks(y_train[songnum]).flatten()))\n",
    "pred_song = np.concatenate((fft_blocks_to_time_blocks(x_train[songnum]).flatten(), fft_blocks_to_time_blocks(pred[songnum]).flatten()))\n",
    "plt.plot(actual_song, label = 'actual')\n",
    "plt.plot(pred_song, label = 'pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songnum = 12\n",
    "# plt.plot(X[songnum,:, 0] * 100)\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,8))\n",
    "actual_song = np.concatenate((fft_blocks_to_time_blocks(x_test[songnum]).flatten(), fft_blocks_to_time_blocks(y_test[songnum]).flatten()))\n",
    "pred_song = np.concatenate((fft_blocks_to_time_blocks(x_test[songnum]).flatten(), fft_blocks_to_time_blocks(predTest[songnum]).flatten()))\n",
    "ax1.plot(actual_song, label = 'actual')\n",
    "ax2.plot(pred_song, label = 'pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio((pred_song * MAX_VAL).astype(int), rate = 4410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 is pretty good\n",
    "# 26 is weird\n",
    "songum = 7\n",
    "curr_input = x_test[songum]\n",
    "curr_song = fft_blocks_to_time_blocks(curr_input).flatten()\n",
    "plt.plot(curr_song)\n",
    "for x in range(30):\n",
    "    prediction = model.predict(np.array([curr_input]))[0]\n",
    "    curr_song = np.concatenate((curr_song, fft_blocks_to_time_blocks(prediction[0:2]).flatten()))\n",
    "    curr_input = np.concatenate((curr_input[2:], prediction[0:2, :]))\n",
    "plt.plot(curr_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(curr_song * MAX_VAL, rate = 4410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_models/ae2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'output.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.io.wavfile.write(data = (curr_song * MAX_VAL).astype(np.int16), rate = 4410, filename = 'interestingdrum.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(curr_song * MAX_VAL).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "#     model.add(tf.keras.layers.Reshape((input_len // reshape_size, reshape_size, 5), input_shape = (input_len, 5)))\n",
    "model.add(tf.keras.layers.InputLayer(input_shape = (500, 1)))\n",
    "# model.add(tf.keras.layers.Conv1D(200, kernel_size = 3, strides=2, padding='same'))\n",
    "model.add(LSTM(512, return_sequences = True))\n",
    "model.add(LSTM(256, return_sequences = False))\n",
    "model.add(Dense(100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainX[:, :, 0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_srnn(input_len, output_len, frame_sizes, unit_sizes):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = (input_len, 1)))\n",
    "    model.add(LSTM(512, return_sequences = True))\n",
    "    for index, (f, u) in enumerate(zip(frame_sizes, unit_sizes)):\n",
    "        model.add(tf.keras.layers.Conv1D(u, kernel_size = f, strides = f, padding='same'))\n",
    "        if(index == len(frame_sizes) - 1):\n",
    "            model.add(LSTM(u, return_sequences = False))\n",
    "        else:\n",
    "            model.add(LSTM(u, return_sequences = True))\n",
    "    model.add(Dense(output_len))\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_srnn(500, 100, [2, 2, 5], [256, 512, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(lr=0.01)\n",
    "met = tf.metrics.MeanAbsoluteError()\n",
    "model.compile(loss=tf.losses.MSE, optimizer=opt, metrics=[met])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempx = np.expand_dims(trainX[:, :, 0],2) * 100\n",
    "tempy = trainY[:,:,0] * 100\n",
    "model.fit(tempx, tempy, epochs=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(tempx)\n",
    "pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_num = 0\n",
    "vals = np.concatenate((tempx[song_num,:,0], pred_val[song_num, :]), axis = 0)\n",
    "real = np.concatenate((tempx[song_num, :,0], tempy[song_num, :]))\n",
    "plt.plot(vals, label = \"predicted\")\n",
    "plt.plot(real, label = \"actual\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tempy[song_num])\n",
    "plt.plot(pred_val[song_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Model\n",
    "def create_gru(input_len, output_len, reshape_size = 2, reg_weight1 = 0, reg_weight2 = 0):\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(tf.keras.layers.Reshape((input_len // reshape_size, reshape_size, 5), input_shape = (input_len, 5)))\n",
    "    model.add(GRU(128, input_shape=(input_len, 5), return_sequences=True))\n",
    "    model.add(GRU(256, return_sequences=False))\n",
    "    model.add(Dense(output_len * 5))\n",
    "    \n",
    "    \n",
    "#     model.add(Dense(output_len * 5))\n",
    "    model.add(tf.keras.layers.Reshape((output_len, 5), input_shape = (output_len * 5, )))\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Model\n",
    "def create_lstm(input_len, output_len, reshape_size = 2, reg_weight1 = 0, reg_weight2 = 0):\n",
    "    model = tf.keras.Sequential()\n",
    "#     model.add(tf.keras.layers.Reshape((input_len // reshape_size, reshape_size, 5), input_shape = (input_len, 5)))\n",
    "    model.add(LSTM(128, input_shape=(input_len, 5), \n",
    "                        return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(LSTM(256, input_shape=(input_len // reshape_size, 128), \n",
    "                        return_sequences=False,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.1))\n",
    "#     model.add(LSTM(512, input_shape=(input_len // reshape_size, 128), \n",
    "#                         return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.1))\n",
    "\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.1))\n",
    "    \n",
    "#     model.add(Dense(512, activation='relu'))\n",
    "#     model.add(BatchNormalization()) #layer normalization\n",
    "    model.add(Dense(output_len * 5))\n",
    "    model.add(tf.keras.layers.Reshape((output_len, 5), input_shape = (output_len * 5, )))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_gru(input_len, output_len, 10)\n",
    "# model = create_encoder_decoder(input_len, output_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# # instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "# # instantiating the model in the strategy scope creates the model on the TPU\n",
    "# with tpu_strategy.scope():\n",
    "opt = tf.optimizers.SGD(lr=0.05)\n",
    "met = tf.metrics.MeanAbsoluteError()\n",
    "model.compile(loss=tf.losses.MSE, optimizer=opt, metrics=[met])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training cell\n",
    "\n",
    "# #early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                                   patience=3,mode='min')\n",
    "\n",
    "#set the file path where the model is saved\n",
    "new_filepath = 'savedmodels/'\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(new_filepath, monitor='val_loss', \n",
    "                                                    verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX,trainY, epochs=100,\n",
    "                             validation_data=(testX,testY),\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/my_model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model to retain\n",
    "new_filepath = 'saved_model/my_model'\n",
    "loaded_model = keras.models.load_model(new_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain using predefined hyperparameters \n",
    "batch_size = [32, 64, 128, 512, 1024, 2048]\n",
    "lr = [0.05, 0.01, 0.01, 0.05, 0.05, 0.05]\n",
    "for i in range(len(batch_size)):\n",
    "    new_history = model.fit(trainX,trainY, epochs=100,\n",
    "                             validation_data=(testX,testY),\n",
    "                             shuffle=True, batch_size=batch_size[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain by manually setting the hyperparameters each run\n",
    "opt = tf.optimizers.SGD(lr=0.05)\n",
    "met = tf.metrics.MeanAbsoluteError()\n",
    "model.compile(loss=tf.losses.MSE, optimizer=opt, metrics=[met])\n",
    "new_history = loaded_model.fit(trainX,trainY, epochs=200,\n",
    "                             validation_data=(testX,testY),\n",
    "                             shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY_invscaled= scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY_invscaled = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate root mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY_invscaled[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "testScore = math.sqrt(mean_squared_error(testY_invscaled[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "trainPredict_reshaped = tf.expand_dims(np.squeeze(trainPredict),1)\n",
    "testPredict_reshaped = tf.expand_dims(np.squeeze(testPredict),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this only works when the predicted output is a number and not a vector\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = tf.expand_dims(np.squeeze(trainPredict),1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(seq_size*2)+1:len(dataset)-1, :] = tf.expand_dims(np.squeeze(testPredict),1)\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will plot an input and its prediction\n",
    "a = 0 #this selects the input sequence\n",
    "out = loaded_model.predict(tf.expand_dims(trainX[a],1))\n",
    "x = scaler.inverse_transform(trainX[a])\n",
    "y = scaler.inverse_transform(out)\n",
    "yy = y.flatten()\n",
    "xx = x.flatten()\n",
    "\n",
    "# print(xx)\n",
    "# print(yy)\n",
    "\n",
    "y1 = np.empty(len(xx)+len(yy))\n",
    "y1[:] = np.nan\n",
    "y1[len(xx):] = yy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(xx)\n",
    "plt.plot(y1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs the prediction for 200 times generate music from given initial sequence\n",
    "#the initial sequence is the same as the one plotted above\n",
    "x_in = trainX[a]\n",
    "song_out = x_in\n",
    "for i in range(200):  \n",
    "    temp = loaded_model.predict(tf.expand_dims(x_in,1))\n",
    "    song_out = np.append(song_out, temp)\n",
    "    x_in = song_out[output_len*(i+1):]\n",
    "    x_in = np.reshape(x_in, (1,-1))\n",
    "\n",
    "song_out = scaler.inverse_transform(song_out).flatten()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(song_out, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play the predicted music\n",
    "int_data = song_out.astype(int)\n",
    "samplerate= 44100/10\n",
    "IPython.display.Audio(int_data, rate=samplerate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
