{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import LSTM, Dropout,Dense, BatchNormalization, GRU\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xData11-50-10.csv\n",
      "yData7-50-10.csv\n",
      "yData13-50-10.csv\n",
      "yData4-50-10.csv\n",
      "xData3-50-10.csv\n",
      "yData1-50-10.csv\n",
      "yData2-50-10.csv\n",
      "yData0-50-10.csv\n",
      "xData5-50-10.csv\n",
      "yData11-50-10.csv\n",
      "yData8-50-10.csv\n",
      "yData9-50-10.csv\n",
      "yData14-50-10.csv\n",
      "xData6-50-10.csv\n",
      "yData3-50-10.csv\n",
      "yData6-50-10.csv\n",
      "xData4-50-10.csv\n",
      "yData10-50-10.csv\n",
      "xData1-50-10.csv\n",
      "xData0-50-10.csv\n",
      "xData14-50-10.csv\n",
      "xData2-50-10.csv\n",
      "yData5-50-10.csv\n",
      "xData9-50-10.csv\n",
      "xData13-50-10.csv\n",
      "xData10-50-10.csv\n",
      "xData8-50-10.csv\n",
      "xData7-50-10.csv\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "\n",
    "#set your music file path\n",
    "directory = '../input/dnnlofi'\n",
    "x_files = []\n",
    "y_files = []\n",
    "for filename in os.listdir(directory):\n",
    "    print(filename)\n",
    "    if('xData' in filename and '-10.csv' in filename):\n",
    "        x_files.append(pd.read_csv(directory + '/' + filename, index_col=0))\n",
    "    elif('yData' in filename and '-10.csv' in filename):\n",
    "        y_files.append(pd.read_csv(directory + '/' + filename, index_col=0))\n",
    "    else:\n",
    "        print('not added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combined = pd.concat(x_files)\n",
    "y_combined = pd.concat(y_files)\n",
    "xy_combined = pd.concat([x_combined, y_combined], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ply the sequence\n",
    "samplerate= 44100/10\n",
    "IPython.display.Audio(X_cut, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xy_combined\n",
    "scaler = StandardScaler()\n",
    "xy_combined_new = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(row, input_len = 300, output_len = 150, stride = 25):\n",
    "    num_segments = (len(row) - (input_len + output_len)) // stride + 1\n",
    "    \n",
    "    X = np.zeros((num_segments, input_len))\n",
    "    y = np.zeros((num_segments, output_len))\n",
    "    \n",
    "    x = 0\n",
    "    for i in range(0, num_segments):\n",
    "        X[i, :] = row[i * stride: i * stride + input_len]\n",
    "        y[i, :] = row[i * stride + input_len: i * stride + input_len + output_len]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (2366, 300)\n",
      "Shape of test set: (263, 300)\n"
     ]
    }
   ],
   "source": [
    "input_len = 300\n",
    "output_len = 150\n",
    "stride = 25\n",
    "window_length = 50\n",
    "X, y = split_sequence(xy_combined_new[0], input_len, output_len, stride)\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.10)\n",
    "print(\"Shape of training set: {}\".format(trainX.shape))\n",
    "print(\"Shape of test set: {}\".format(testX.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3d861059fa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c4d72a835b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m \u001b[0;31m#length of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of training set: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of time steps to look back \n",
    "#Larger sequences (look further back) may improve forecasting.\n",
    "seq_size = 300 \n",
    "output_len = 150 #length of the output\n",
    "\n",
    "trainX, trainY = to_sequences(train, seq_size, output_len)\n",
    "testX, testY = to_sequences(test, seq_size, output_len)\n",
    "print(\"Shape of training set: {}\".format(trainX.shape))\n",
    "print(\"Shape of test set: {}\".format(testX.shape))\n",
    "\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU model\n",
    "#run either the GRU or the LSTM model and tune parameters for each to see which works best\n",
    "def create_gru(reg_weight1 = 0, reg_weight2 = 0):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(GRU(512, input_shape=(None,seq_size), \n",
    "                        return_sequences=True,\n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(512, return_sequences=False, kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_len))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Model\n",
    "def create_lstm(input_len, output_len, reg_weight1 = 0, reg_weight2 = 0):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(LSTM(1024, input_shape=(None, input_len), \n",
    "                        return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    # model.add(LSTM(1024, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # #model.add(Dropout(0.1))\n",
    "\n",
    "    # model.add(LSTM(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # #model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(LSTM(512, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(1024, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(1024, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(1024, return_sequences=True,kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(1024, return_sequences=False, kernel_regularizer=regularizers.l1_l2(l1=reg_weight1, l2=reg_weight2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_len))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_decoder(inp_dim, out_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(LSTM(1024, activation='relu', input_shape=(inp_dim,1), return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.RepeatVector(out_dim))\n",
    "    model.add(LSTM(1024, activation='relu', return_sequences=True))\n",
    "    model.add(tf.keras.layers.TimeDistributed(Dense(1)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, None, 1024)        5427200   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 1024)        8392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 1024)        8392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, None, 1024)        8392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1024)              8392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150)               9750      \n",
      "=================================================================\n",
      "Total params: 39,094,102\n",
      "Trainable params: 39,083,734\n",
      "Non-trainable params: 10,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_encoder_decoder(input_len, output_len)\n",
    "model = create_lstm(input_len, output_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = tf.expand_dims(trainX, 1)\n",
    "trainY = tf.expand_dims(trainY, 1)\n",
    "testX = tf.expand_dims(testX, 1)\n",
    "testY = tf.expand_dims(testY, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - 12s 38ms/step - loss: 1.4407 - mean_absolute_error: 0.9392 - val_loss: 1.0710 - val_mean_absolute_error: 0.8082\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.2294 - mean_absolute_error: 0.8625 - val_loss: 1.1172 - val_mean_absolute_error: 0.8271\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 1.1834 - mean_absolute_error: 0.8465 - val_loss: 1.1247 - val_mean_absolute_error: 0.8301\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.2272 - mean_absolute_error: 0.8558 - val_loss: 1.0985 - val_mean_absolute_error: 0.8196\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1603 - mean_absolute_error: 0.8365 - val_loss: 1.0510 - val_mean_absolute_error: 0.8001\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1745 - mean_absolute_error: 0.8382 - val_loss: 1.0187 - val_mean_absolute_error: 0.7871\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 1.1482 - mean_absolute_error: 0.8326 - val_loss: 1.0091 - val_mean_absolute_error: 0.7834\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1562 - mean_absolute_error: 0.8326 - val_loss: 1.0074 - val_mean_absolute_error: 0.7826\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1593 - mean_absolute_error: 0.8339 - val_loss: 1.0068 - val_mean_absolute_error: 0.7823\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1936 - mean_absolute_error: 0.8464 - val_loss: 1.0060 - val_mean_absolute_error: 0.7820\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1729 - mean_absolute_error: 0.8380 - val_loss: 1.0053 - val_mean_absolute_error: 0.7817\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1605 - mean_absolute_error: 0.8348 - val_loss: 1.0045 - val_mean_absolute_error: 0.7813\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 1.1813 - mean_absolute_error: 0.8392 - val_loss: 1.0040 - val_mean_absolute_error: 0.7811\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 1.1478 - mean_absolute_error: 0.8297 - val_loss: 1.0035 - val_mean_absolute_error: 0.7810\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1029 - mean_absolute_error: 0.8171 - val_loss: 1.0031 - val_mean_absolute_error: 0.7808\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1704 - mean_absolute_error: 0.8350 - val_loss: 1.0027 - val_mean_absolute_error: 0.7808\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1458 - mean_absolute_error: 0.8276 - val_loss: 1.0024 - val_mean_absolute_error: 0.7807\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1674 - mean_absolute_error: 0.8343 - val_loss: 1.0021 - val_mean_absolute_error: 0.7805\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1694 - mean_absolute_error: 0.8352 - val_loss: 1.0019 - val_mean_absolute_error: 0.7805\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1326 - mean_absolute_error: 0.8268 - val_loss: 1.0016 - val_mean_absolute_error: 0.7804\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1436 - mean_absolute_error: 0.8284 - val_loss: 1.0015 - val_mean_absolute_error: 0.7803\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1255 - mean_absolute_error: 0.8243 - val_loss: 1.0013 - val_mean_absolute_error: 0.7803\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1589 - mean_absolute_error: 0.8334 - val_loss: 1.0012 - val_mean_absolute_error: 0.7802\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1678 - mean_absolute_error: 0.8361 - val_loss: 1.0010 - val_mean_absolute_error: 0.7802\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1214 - mean_absolute_error: 0.8226 - val_loss: 1.0009 - val_mean_absolute_error: 0.7802\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1593 - mean_absolute_error: 0.8316 - val_loss: 1.0008 - val_mean_absolute_error: 0.7802\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1505 - mean_absolute_error: 0.8309 - val_loss: 1.0007 - val_mean_absolute_error: 0.7801\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1826 - mean_absolute_error: 0.8403 - val_loss: 1.0006 - val_mean_absolute_error: 0.7801\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1435 - mean_absolute_error: 0.8295 - val_loss: 1.0006 - val_mean_absolute_error: 0.7801\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1629 - mean_absolute_error: 0.8347 - val_loss: 1.0005 - val_mean_absolute_error: 0.7800\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1378 - mean_absolute_error: 0.8247 - val_loss: 1.0004 - val_mean_absolute_error: 0.7800\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1288 - mean_absolute_error: 0.8256 - val_loss: 1.0004 - val_mean_absolute_error: 0.7800\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1241 - mean_absolute_error: 0.8252 - val_loss: 1.0003 - val_mean_absolute_error: 0.7800\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1393 - mean_absolute_error: 0.8281 - val_loss: 1.0002 - val_mean_absolute_error: 0.7800\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1267 - mean_absolute_error: 0.8252 - val_loss: 1.0002 - val_mean_absolute_error: 0.7799\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1803 - mean_absolute_error: 0.8423 - val_loss: 1.0002 - val_mean_absolute_error: 0.7799\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1482 - mean_absolute_error: 0.8322 - val_loss: 1.0001 - val_mean_absolute_error: 0.7799\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1412 - mean_absolute_error: 0.8250 - val_loss: 1.0001 - val_mean_absolute_error: 0.7799\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1855 - mean_absolute_error: 0.8457 - val_loss: 1.0001 - val_mean_absolute_error: 0.7799\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1445 - mean_absolute_error: 0.8276 - val_loss: 1.0000 - val_mean_absolute_error: 0.7799\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1340 - mean_absolute_error: 0.8263 - val_loss: 1.0000 - val_mean_absolute_error: 0.7799\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1520 - mean_absolute_error: 0.8320 - val_loss: 1.0000 - val_mean_absolute_error: 0.7798\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 1.1172 - mean_absolute_error: 0.8202 - val_loss: 0.9999 - val_mean_absolute_error: 0.7798\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1561 - mean_absolute_error: 0.8311 - val_loss: 0.9999 - val_mean_absolute_error: 0.7798\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1430 - mean_absolute_error: 0.8284 - val_loss: 0.9999 - val_mean_absolute_error: 0.7798\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1825 - mean_absolute_error: 0.8407 - val_loss: 0.9999 - val_mean_absolute_error: 0.7798\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1283 - mean_absolute_error: 0.8273 - val_loss: 0.9999 - val_mean_absolute_error: 0.7798\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1222 - mean_absolute_error: 0.8230 - val_loss: 0.9998 - val_mean_absolute_error: 0.7798\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1219 - mean_absolute_error: 0.8218 - val_loss: 0.9998 - val_mean_absolute_error: 0.7798\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1636 - mean_absolute_error: 0.8322 - val_loss: 0.9998 - val_mean_absolute_error: 0.7798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1681 - mean_absolute_error: 0.8353 - val_loss: 0.9998 - val_mean_absolute_error: 0.7798\n",
      "Epoch 52/100\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 1.1234 - mean_absolute_error: 0.8217 - val_loss: 0.9998 - val_mean_absolute_error: 0.7798\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1762 - mean_absolute_error: 0.8391 - val_loss: 0.9997 - val_mean_absolute_error: 0.7798\n",
      "Epoch 54/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1524 - mean_absolute_error: 0.8306 - val_loss: 0.9997 - val_mean_absolute_error: 0.7798\n",
      "Epoch 55/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1689 - mean_absolute_error: 0.8398 - val_loss: 0.9997 - val_mean_absolute_error: 0.7797\n",
      "Epoch 56/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1681 - mean_absolute_error: 0.8318 - val_loss: 0.9997 - val_mean_absolute_error: 0.7797\n",
      "Epoch 57/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1626 - mean_absolute_error: 0.8318 - val_loss: 0.9997 - val_mean_absolute_error: 0.7797\n",
      "Epoch 58/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1452 - mean_absolute_error: 0.8305 - val_loss: 0.9997 - val_mean_absolute_error: 0.7797\n",
      "Epoch 59/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1449 - mean_absolute_error: 0.8292 - val_loss: 0.9997 - val_mean_absolute_error: 0.7797\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1305 - mean_absolute_error: 0.8237 - val_loss: 0.9997 - val_mean_absolute_error: 0.7797\n",
      "Epoch 61/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1627 - mean_absolute_error: 0.8349 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 62/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1527 - mean_absolute_error: 0.8306 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 63/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1502 - mean_absolute_error: 0.8315 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1585 - mean_absolute_error: 0.8351 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1416 - mean_absolute_error: 0.8295 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 1.1350 - mean_absolute_error: 0.8273 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1128 - mean_absolute_error: 0.8192 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1424 - mean_absolute_error: 0.8293 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1362 - mean_absolute_error: 0.8269 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1652 - mean_absolute_error: 0.8358 - val_loss: 0.9996 - val_mean_absolute_error: 0.7797\n",
      "Epoch 71/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1659 - mean_absolute_error: 0.8375 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.1373 - mean_absolute_error: 0.8257 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 73/100\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 1.1515 - mean_absolute_error: 0.8349 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1462 - mean_absolute_error: 0.8296 - val_loss: 0.9995 - val_mean_absolute_error: 0.7796\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1897 - mean_absolute_error: 0.8396 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 76/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1296 - mean_absolute_error: 0.8255 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 77/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1271 - mean_absolute_error: 0.8250 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 78/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1372 - mean_absolute_error: 0.8274 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1441 - mean_absolute_error: 0.8263 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1272 - mean_absolute_error: 0.8225 - val_loss: 0.9995 - val_mean_absolute_error: 0.7797\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 1.1482 - mean_absolute_error: 0.8301 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 82/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1524 - mean_absolute_error: 0.8330 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1358 - mean_absolute_error: 0.8277 - val_loss: 0.9994 - val_mean_absolute_error: 0.7797\n",
      "Epoch 84/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1016 - mean_absolute_error: 0.8180 - val_loss: 0.9994 - val_mean_absolute_error: 0.7797\n",
      "Epoch 85/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1564 - mean_absolute_error: 0.8334 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 86/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1318 - mean_absolute_error: 0.8257 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 87/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1588 - mean_absolute_error: 0.8347 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 88/100\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 1.1448 - mean_absolute_error: 0.8303 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 1.1869 - mean_absolute_error: 0.8425 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 90/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1244 - mean_absolute_error: 0.8223 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 91/100\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 1.1496 - mean_absolute_error: 0.8307 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1482 - mean_absolute_error: 0.8278 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1499 - mean_absolute_error: 0.8309 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1247 - mean_absolute_error: 0.8217 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 95/100\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 1.1426 - mean_absolute_error: 0.8279 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1363 - mean_absolute_error: 0.8293 - val_loss: 0.9993 - val_mean_absolute_error: 0.7796\n",
      "Epoch 97/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1755 - mean_absolute_error: 0.8377 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 98/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1479 - mean_absolute_error: 0.8294 - val_loss: 0.9994 - val_mean_absolute_error: 0.7796\n",
      "Epoch 99/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1134 - mean_absolute_error: 0.8185 - val_loss: 0.9993 - val_mean_absolute_error: 0.7796\n",
      "Epoch 100/100\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.1536 - mean_absolute_error: 0.8328 - val_loss: 0.9993 - val_mean_absolute_error: 0.7796\n"
     ]
    }
   ],
   "source": [
    "# main training cell\n",
    "\n",
    "# #early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                                   patience=3,mode='min')\n",
    "opt = tf.optimizers.SGD(lr=0.05)\n",
    "met = tf.metrics.MeanAbsoluteError()\n",
    "model.compile(loss=tf.losses.MSE, optimizer=opt, metrics=[met])\n",
    "\n",
    "#set the file path where the model is saved\n",
    "new_filepath = 'savedmodels/'\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(new_filepath, monitor='val_loss', \n",
    "                                                    verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX,trainY, epochs=100,\n",
    "                             validation_data=(testX,testY),\n",
    "                             shuffle=True)\n",
    "# history = model.fit(tf.expand_dims(trainX[:500,:], -1),tf.expand_dims(trainY[:500,:], -1), epochs=100,\n",
    "#                              validation_data=(tf.expand_dims(testX[:100,:], -1),tf.expand_dims(testY[:100,:], -1)),\n",
    "#                              shuffle=True, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model to retain\n",
    "new_filepath = r'C:\\Users\\16177\\Documents\\Deep Learning Class Spring 2021\\project\\dnn-lofi-generation-main\\practice_models\\jason\\saved_models'\n",
    "loaded_model = keras.models.load_model(new_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 300)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4a11179ccd90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     new_history = model.fit(trainX,trainY, epochs=200,\n\u001b[1;32m      9\u001b[0m                              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                              shuffle=True, batch_size=batch_size[i])\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 300)\n"
     ]
    }
   ],
   "source": [
    "#retrain using predefined hyperparameters \n",
    "batch_size = [32, 32, 64, 64, 128, 256, 512, 1024, 2048]\n",
    "lr = [0.05, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "for i in range(len(batch_size)):\n",
    "    opt = tf.optimizers.SGD(lr=lr[i])\n",
    "    met = tf.metrics.MeanAbsoluteError()\n",
    "    model.compile(loss=tf.losses.MSE, optimizer=opt, metrics=[met])\n",
    "    new_history = model.fit(trainX,trainY, epochs=200,\n",
    "                             validation_data=(testX,testY),\n",
    "                             shuffle=True, batch_size=batch_size[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain by manually setting the hyperparameters each run\n",
    "opt = tf.optimizers.SGD(lr=0.05)\n",
    "met = tf.metrics.MeanAbsoluteError()\n",
    "model.compile(loss=tf.losses.MSE, optimizer=opt, metrics=[met])\n",
    "new_history = loaded_model.fit(trainX,trainY, epochs=200,\n",
    "                             validation_data=(testX,testY),\n",
    "                             shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainY_invscaled.shape, trainPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY_invscaled= scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY_invscaled = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate root mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY_invscaled[0], trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "testScore = math.sqrt(mean_squared_error(testY_invscaled[0], testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "trainPredict_reshaped = tf.expand_dims(np.squeeze(trainPredict),1)\n",
    "testPredict_reshaped = tf.expand_dims(np.squeeze(testPredict),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this only works when the predicted output is a number and not a vector\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = tf.expand_dims(np.squeeze(trainPredict),1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(seq_size*2)+1:len(dataset)-1, :] = tf.expand_dims(np.squeeze(testPredict),1)\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will plot an input and its prediction\n",
    "a = 0 #this selects the input sequence\n",
    "out = loaded_model.predict(tf.expand_dims(trainX[a],1))\n",
    "x = scaler.inverse_transform(trainX[a])\n",
    "y = scaler.inverse_transform(out)\n",
    "yy = y.flatten()\n",
    "xx = x.flatten()\n",
    "\n",
    "# print(xx)\n",
    "# print(yy)\n",
    "\n",
    "y1 = np.empty(len(xx)+len(yy))\n",
    "y1[:] = np.nan\n",
    "y1[len(xx):] = yy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(xx)\n",
    "plt.plot(y1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs the prediction for 200 times generate music from given initial sequence\n",
    "#the initial sequence is the same as the one plotted above\n",
    "x_in = trainX[a]\n",
    "song_out = x_in\n",
    "for i in range(200):  \n",
    "    temp = loaded_model.predict(tf.expand_dims(x_in,1))\n",
    "    song_out = np.append(song_out, temp)\n",
    "    x_in = song_out[output_len*(i+1):]\n",
    "    x_in = np.reshape(x_in, (1,-1))\n",
    "\n",
    "song_out = scaler.inverse_transform(song_out).flatten()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(song_out, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play the predicted music\n",
    "int_data = song_out.astype(int)\n",
    "samplerate= 44100/10\n",
    "IPython.display.Audio(int_data, rate=samplerate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
